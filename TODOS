CODE
[x] median filters for controls
[x] standardization for controls
[ ] remove audiotools requirement
    [x] from vampnet
    [ ] from DAC? or remove DAC? or minify DAC?
[ ] timbretrap conditioning? 

DATASETS
[ ] a dataset for melodic // harmonic sounds? 
    - [ ] maybe do hpss on the audio as preprocessing or something crazy
        - [ ] or demucs
        - [ ] or just use a melodic
[ ] orchestral dataset? 
[ ] jazz? 
[ ] minimalist // electroacoustic? 


PUREDATA
[ ] midi sync (for beat-based music)
[ ] save loops in a bank (for both)
[ ] stereo panning
[ ] multiple channels at once (goes w/ stereo panning)


EXPERIMENTS
[x] need quantization // standardization?
    - YES. todo: compare rms, rmsq128, rmsq16 w/ test framework
[ ] stemgen vs vampnet? 
[ ] what's the right cfg value? 
[ ] train a dac without quantizer drop for better codebook-drop prompting? 


HARDWARE:
[ ] case needs to be a bit taller to acommodate the USB-C panel mount 

TEST FRAMEWORK:
- small listening test set
    [ ] collect 5 example audio files of different possible input sounds
        - solo instrument (violin // sax // etc)
        - singing
        - drum beat // percussion
        - chord instrument (piano // guitar)
        - ambient // synth
    [ ] write a script that sweeps over hyperparameters or different model checkpoints
        for each category: 
            - run the model:
                - use an audio file from 1 category (singing) as input, 
                - use an audio file from another category (drum beat) as target
            - save the generated audio file along with the input and target in a folder
- objective metrics
    [ ] support doing this with large numbers of audio file (10k) and compute metrics like FAD
        on the generated outputs


~~~~~~~
for an electroacoustic performance
[ ] evaluate actual interactivity with an instrument


~~~~~~~
[ ] collect a dataset of sonic imitations for musicmaking?!!?!
[ ] hire people? 
 - VS OTHER DATASETS: IT'S ALIGNED IN TIME
    - others: taptamdrum